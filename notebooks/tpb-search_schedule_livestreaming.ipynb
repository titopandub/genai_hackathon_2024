{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from annoy import AnnoyIndex\n",
    "import pandas as pd\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "vertexai.init(project=\"vidio-quiz-prod\", location=\"asia-southeast1\")\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual\")\n",
    "model = VertexAI(model_name=\"gemini-pro\", temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You as a search expert, you have tool Elasticsearch to perform lexical search for live streaming schedule.\n",
      "\n",
      "Given user query, give the exact query to ask to lexical search, clean up any unnecessary word that might pollute the search query, especially word like `kapan`, `pertandingan`, `vs`.\n",
      "\n",
      "User Query: {user_query}\n",
      "Query to Lexical Search:\n"
     ]
    }
   ],
   "source": [
    "template_asking_elasticsearch = (\n",
    "    \"You as a search expert, you have tool Elasticsearch to perform lexical search for live streaming schedule.\\n\\n\"\n",
    "    \"Given user query, give the exact query to ask to lexical search, clean up any unnecessary word that might pollute the search query, especially word like `kapan`, `pertandingan`, `vs`.\\n\\n\"\n",
    "    \"User Query: {user_query}\\n\"\n",
    "    \"Query to Lexical Search:\"\n",
    ")\n",
    "prompt_elasticsearch = ChatPromptTemplate.from_template(template_asking_elasticsearch)\n",
    "chain_elasticsearch = prompt_elasticsearch | model | StrOutputParser()\n",
    "print(template_asking_elasticsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newcastle united west ham united'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_elasticsearch.invoke({\"user_query\": \"when the match newcastle united vs west ham united?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_hackathon_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
